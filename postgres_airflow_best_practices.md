# Apache Airflow PostgreSQL Best Practices Guide

## ğŸ“– ê°œìš”

Apache Airflowì—ì„œ PostgreSQL ë°ì´í„°ë² ì´ìŠ¤ì™€ íš¨ê³¼ì ìœ¼ë¡œ ì‘ì—…í•˜ê¸° ìœ„í•œ ì™„ì „í•œ ê°€ì´ë“œì…ë‹ˆë‹¤. PostgreSQL Hookì€ ë‹¨ìˆœí•œ ì—°ê²° ë„êµ¬ê°€ ì•„ë‹Œ ê°•ë ¥í•œ ë°ì´í„°ë² ì´ìŠ¤ ì›Œí¬í”Œë¡œìš° ì—”ì§„ì…ë‹ˆë‹¤.

## ğŸ¯ PostgreSQL Hookì˜ ì‹¤ì œ ê¸°ëŠ¥

PostgreSQL Hookì€ ë‹¨ìˆœí•œ ì—°ê²° ì •ë³´ë§Œ ì œê³µí•˜ëŠ” ê²ƒì´ ì•„ë‹ˆë¼ ë‹¤ìŒê³¼ ê°™ì€ ê°•ë ¥í•œ ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤:

### Core Methods
- `get_records()`: ì¿¼ë¦¬ ê²°ê³¼ë¥¼ ë ˆì½”ë“œ ë¦¬ìŠ¤íŠ¸ë¡œ ë°˜í™˜
- `get_first()`: ì²« ë²ˆì§¸ ê²°ê³¼ë§Œ ë°˜í™˜
- `run()`: SQL ì¿¼ë¦¬ ì‹¤í–‰
- `insert_rows()`: ëŒ€ëŸ‰ ë°ì´í„° ì‚½ì… (executemany ì‚¬ìš©ìœ¼ë¡œ ì„±ëŠ¥ ìµœì í™”)
- `get_pandas_df()`: ê²°ê³¼ë¥¼ Pandas DataFrameìœ¼ë¡œ ë°˜í™˜

## ğŸ› ï¸ Best Practices

### 1. ì˜¬ë°”ë¥¸ Hook ì¸ìŠ¤í„´ìŠ¤í™”

```python
from airflow.providers.postgres.hooks.postgres import PostgresHook
from airflow.models import BaseOperator

class CustomDBOperator(BaseOperator):
    def __init__(self, postgres_conn_id: str, database: str, **kwargs):
        super().__init__(**kwargs)
        self.postgres_conn_id = postgres_conn_id
        self.database = database

    def execute(self, context):
        # âœ… execute ë©”ì„œë“œ ë‚´ì—ì„œ hook ìƒì„± (DAG íŒŒì‹± ì‹œ ì—°ê²° ë°©ì§€)
        hook = PostgresHook(postgres_conn_id=self.postgres_conn_id, database=self.database)
        sql = "SELECT name FROM users WHERE active = true"
        result = hook.get_first(sql)
        return result
```

**í•µì‹¬ í¬ì¸íŠ¸:**
- Hookì„ `__init__` ë©”ì„œë“œê°€ ì•„ë‹Œ `execute` ë©”ì„œë“œ ë‚´ì—ì„œ ìƒì„±
- DAG íŒŒì‹± ì‹œ ë¶ˆí•„ìš”í•œ ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ë°©ì§€

### 2. SQLExecuteQueryOperator í™œìš©

#### ê¸°ë³¸ ì¿¼ë¦¬ ì‹¤í–‰
```python
from airflow.providers.common.sql.operators.sql import SQLExecuteQueryOperator

# ê¸°ë³¸ ì¿¼ë¦¬ ì‹¤í–‰
execute_query = SQLExecuteQueryOperator(
    task_id="execute_query",
    conn_id="postgres_default",
    sql="SELECT * FROM my_table WHERE created_date >= '2023-01-01'",
    autocommit=True  # ìë™ ì»¤ë°‹
)
```

#### íŒŒë¼ë¯¸í„°í™”ëœ ì¿¼ë¦¬ (SQL ì¸ì ì…˜ ë°©ì§€)
```python
# ğŸ”’ ë³´ì•ˆ: íŒŒë¼ë¯¸í„°í™”ëœ ì¿¼ë¦¬ ì‚¬ìš©
parameterized_query = SQLExecuteQueryOperator(
    task_id="parameterized_query", 
    conn_id="postgres_default",
    sql="SELECT * FROM users WHERE user_id = %(user_id)s AND status = %(status)s",
    parameters={"user_id": 123, "status": "active"}
)
```

#### íŒŒì¼ ê¸°ë°˜ SQL + í…œí”Œë¦¿
```sql
-- sql/user_report.sql
SELECT * FROM users 
WHERE created_date BETWEEN SYMMETRIC {{ params.start_date }} AND {{ params.end_date }}
  AND department = {{ params.department }}
```

```python
user_report = SQLExecuteQueryOperator(
    task_id="user_report",
    conn_id="postgres_default", 
    sql="sql/user_report.sql",
    params={
        "start_date": "2023-01-01", 
        "end_date": "2023-12-31",
        "department": "'Engineering'"
    }
)
```

### 3. ê³ ì„±ëŠ¥ ë°ì´í„° ì‘ì—…

#### ëŒ€ëŸ‰ ë°ì´í„° ì‚½ì… ìµœì í™”
```python
# âš¡ executemany ì‚¬ìš©ìœ¼ë¡œ ì„±ëŠ¥ í–¥ìƒ
hook = PostgresHook(postgres_conn_id="postgres_default")
bulk_data = [
    (1, 'John', 'john@email.com'),
    (2, 'Jane', 'jane@email.com'),
    (3, 'Bob', 'bob@email.com')
]

hook.insert_rows(
    table="users",
    rows=bulk_data,
    target_fields=["id", "name", "email"],
    autocommit=True  # ì„±ëŠ¥ í–¥ìƒ
)
```

#### ì„œë²„ ì‚¬ì´ë“œ ì»¤ì„œ (ëŒ€ìš©ëŸ‰ ê²°ê³¼ì…‹)
```python
from airflow.providers.google.transfers.postgres_to_gcs import PostgresToGCSOperator

# ğŸ—„ï¸ ë©”ëª¨ë¦¬ íš¨ìœ¨ì ì¸ ëŒ€ìš©ëŸ‰ ë°ì´í„° ì²˜ë¦¬
large_export = PostgresToGCSOperator(
    task_id="export_big_table",
    sql="SELECT * FROM transactions WHERE date >= '2023-01-01'",
    use_server_side_cursor=True,  # ë©”ëª¨ë¦¬ íš¨ìœ¨ì 
    postgres_conn_id="postgres_default",
    bucket="my-data-bucket",
    filename="transactions_export.csv"
)
```

### 4. ì—°ê²° ì„¤ì • ìµœì í™”

#### SQLAlchemy ì—°ê²° ë¬¸ìì—´
```python
# ğŸ”— SQLAlchemy 1.4+ í˜¸í™˜ í˜•ì‹
connection_string = "postgresql+psycopg2://username:password@host:5432/database"

# í™˜ê²½ ë³€ìˆ˜ ì„¤ì • ì˜ˆì‹œ
export AIRFLOW__DATABASE__SQL_ALCHEMY_CONN="postgresql+psycopg2://airflow_user:airflow_pass@localhost:5432/airflow_db"
```

#### ê³ ê¸‰ ì—°ê²° ì˜µì…˜
```python
# ğŸ“‹ ìŠ¤í‚¤ë§ˆ ë° ê³ ê¸‰ ì˜µì…˜ ì„¤ì •
advanced_task = SQLExecuteQueryOperator(
    task_id="advanced_postgres_task",
    conn_id="postgres_default",
    sql="SELECT * FROM analytics.user_metrics",
    hook_params={
        "options": "-c search_path=analytics,public",  # ìŠ¤í‚¤ë§ˆ ê²½ë¡œ ì„¤ì •
        "enable_log_db_messages": True  # DB ë©”ì‹œì§€ ë¡œê¹… í™œì„±í™”
    }
)
```

## ğŸ›¡ï¸ ë³´ì•ˆ Best Practices

### 1. SQL ì¸ì ì…˜ ë°©ì§€
```python
# âŒ ìœ„í—˜: ë¬¸ìì—´ í¬ë§·íŒ… ì‚¬ìš©
dangerous_query = f"SELECT * FROM users WHERE name = '{user_input}'"

# âœ… ì•ˆì „: íŒŒë¼ë¯¸í„°í™”ëœ ì¿¼ë¦¬ ì‚¬ìš©
safe_query = SQLExecuteQueryOperator(
    task_id="safe_query",
    conn_id="postgres_default",
    sql="SELECT * FROM users WHERE name = %(name)s",
    parameters={"name": user_input}
)
```

### 2. ë°ì´í„°ë² ì´ìŠ¤ ê¶Œí•œ ì„¤ì •
```sql
-- PostgreSQL ì‚¬ìš©ì ë° ê¶Œí•œ ì„¤ì •
CREATE USER airflow_user WITH PASSWORD 'secure_password';
CREATE DATABASE airflow_db OWNER airflow_user;
GRANT ALL PRIVILEGES ON DATABASE airflow_db TO airflow_user;

-- PostgreSQL 15+ ì¶”ê°€ ê¶Œí•œ
GRANT ALL ON SCHEMA public TO airflow_user;
ALTER USER airflow_user SET search_path = public;
```

### 3. ì—°ê²° ì •ë³´ ë³´ì•ˆ
```python
# Connectionì— ë¯¼ê°í•œ ì •ë³´ ì €ì¥ ì‹œ Airflow UI ë˜ëŠ” í™˜ê²½ ë³€ìˆ˜ ì‚¬ìš©
# ì½”ë“œì— í•˜ë“œì½”ë”©í•˜ì§€ ë§ ê²ƒ
```

## âš¡ ì„±ëŠ¥ ìµœì í™” Tips

### 1. ì—°ê²° í’€ë§
```yaml
# pgbouncerë¥¼ í†µí•œ ì—°ê²° í’€ë§ (Helm ì°¨íŠ¸)
pgbouncer:
  enabled: true
```

### 2. ì¿¼ë¦¬ ìµœì í™”
```sql
-- ì •ê¸°ì ì¸ í†µê³„ ì—…ë°ì´íŠ¸
ANALYZE;

-- ì¸ë±ìŠ¤ í™œìš©
CREATE INDEX idx_users_created_date ON users(created_date);
CREATE INDEX idx_users_status ON users(status) WHERE status = 'active';
```

### 3. ë°°ì¹˜ ì²˜ë¦¬
```python
# ì—¬ëŸ¬ ì‘ì€ íŠ¸ëœì­ì…˜ë³´ë‹¤ í•˜ë‚˜ì˜ í° íŠ¸ëœì­ì…˜ ì„ í˜¸
with PostgresHook(postgres_conn_id="postgres_default").get_conn() as conn:
    with conn.cursor() as cursor:
        for batch in data_batches:
            cursor.executemany(insert_query, batch)
        conn.commit()
```


## ğŸ“š ì°¸ê³  ìë£Œ

### ê³µì‹ ë¬¸ì„œ
- [Apache Airflow PostgreSQL Provider](https://airflow.apache.org/docs/apache-airflow-providers-postgres/stable/)
- [PostgreSQL Hooks Documentation](https://airflow.apache.org/docs/apache-airflow-providers-postgres/stable/hooks.html)
- [SQLExecuteQueryOperator Documentation](https://airflow.apache.org/docs/apache-airflow-providers-common-sql/stable/operators.html)

### ì„¤ì¹˜ ë° ì„¤ì •
```bash
# PostgreSQL Provider ì„¤ì¹˜
pip install 'apache-airflow[postgres]'

# ë˜ëŠ” ê°œë³„ ì„¤ì¹˜
pip install apache-airflow-providers-postgres
```

### ì»¤ë®¤ë‹ˆí‹° ë¦¬ì†ŒìŠ¤
- [Airflow GitHub Repository](https://github.com/apache/airflow)
- [PostgreSQL Provider Issues](https://github.com/apache/airflow/labels/area%3Aproviders%2Fpostgres)
- [Airflow Community Slack](https://apache-airflow-slack.herokuapp.com/)

## ğŸš€ ì£¼ìš” ì¥ì 

1. **ì„±ëŠ¥**: executemanyë¥¼ í†µí•œ ëŒ€ëŸ‰ ì‘ì—… ìµœì í™”
2. **ë³´ì•ˆ**: íŒŒë¼ë¯¸í„°í™”ëœ ì¿¼ë¦¬ë¡œ SQL ì¸ì ì…˜ ë°©ì§€
3. **í™•ì¥ì„±**: ì„œë²„ ì‚¬ì´ë“œ ì»¤ì„œì™€ ì—°ê²° í’€ë§
4. **ìœ ì§€ë³´ìˆ˜ì„±**: íŒŒì¼ ê¸°ë°˜ SQLê³¼ í…œí”Œë¦¿ í™œìš©
5. **ëª¨ë‹ˆí„°ë§**: ìƒì„¸í•œ ë¡œê¹… ë° ì˜¤ë¥˜ ì²˜ë¦¬

## ğŸ“ ì²´í¬ë¦¬ìŠ¤íŠ¸

### ê°œë°œ ì‹œ
- [ ] Hookì„ execute ë©”ì„œë“œ ë‚´ì—ì„œ ì¸ìŠ¤í„´ìŠ¤í™”
- [ ] íŒŒë¼ë¯¸í„°í™”ëœ ì¿¼ë¦¬ ì‚¬ìš©
- [ ] ì ì ˆí•œ autocommit ì„¤ì •
- [ ] ì˜¤ë¥˜ ì²˜ë¦¬ ë° ë¡œê¹… êµ¬í˜„

### í”„ë¡œë•ì…˜ ë°°í¬ ì‹œ
- [ ] ì™¸ë¶€ PostgreSQL ë°ì´í„°ë² ì´ìŠ¤ ì‚¬ìš©
- [ ] ì—°ê²° í’€ë§ ì„¤ì • (pgbouncer)
- [ ] ì ì ˆí•œ ì‚¬ìš©ì ê¶Œí•œ ì„¤ì •
- [ ] ì •ê¸°ì ì¸ ANALYZE ì‹¤í–‰ ìŠ¤ì¼€ì¤„ë§
- [ ] ëª¨ë‹ˆí„°ë§ ë° ì•Œë¦¼ ì„¤ì •

---

**ì‘ì„±ì¼**: {{ ds }}  
**ë²„ì „**: 1.0  
**ë§ˆì§€ë§‰ ì—…ë°ì´íŠ¸**: {{ ts }}